{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levatamos Fermionic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 14:40:38.727409: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-17 14:40:38.727432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-17 14:40:38.728287: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-17 14:40:38.733194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-17 14:40:39.415648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import openfermion as of\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from openfermion.utils import commutator, count_qubits, hermitian_conjugated\n",
    "import functools\n",
    "import concurrent.futures\n",
    "from numba import njit\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import sparse\n",
    "import itertools\n",
    "import linecache\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Generación de base\n",
    "class fixed_basis:\n",
    "    @staticmethod\n",
    "    def int_to_bin(k, d):\n",
    "        return np.base_repr(k, 2).zfill(d)\n",
    "\n",
    "    @staticmethod\n",
    "    def bin_to_op(b):\n",
    "        tups = [(i, 1) for i, k in list(enumerate(list(b))) if k == '1']\n",
    "        return of.FermionOperator(tups)\n",
    "\n",
    "    def idx_to_repr(self, idx):\n",
    "        return self.canonicals[idx]\n",
    "\n",
    "    def opr_to_idx(self, opr):\n",
    "        for i in range(self.size): # Evitar esto ordenando opr\n",
    "            if self.base[i] == opr:\n",
    "                return i\n",
    "\n",
    "    # Calcula el valor medio a partir del indice del vector y el operador\n",
    "    def idx_mean_val(self, idx: int, op: of.FermionOperator):\n",
    "        vec = self.idx_to_repr(idx)\n",
    "        return np.real(np.transpose(vec) @ of.get_sparse_operator(op, n_qubits=self.d) @ vec)\n",
    "\n",
    "    # Calcula el valor medio a partir de un estado y el operador\n",
    "    def mean_val(self, vec, op):\n",
    "        idx = self.opr_to_idx(vec)\n",
    "        return self.idx_mean_val(idx, op)\n",
    "\n",
    "    # Calcula la contracción de un operador sobre dos estados dados\n",
    "    def idx_contraction(self, idx_1, idx_2, op):\n",
    "        rep = lambda x: self.idx_to_repr(x)\n",
    "        return np.real(np.transpose(rep(idx_1)) @ of.get_sparse_operator(op, n_qubits=self.d) @ rep(idx_2))\n",
    "\n",
    "    def create_basis(self, d, num = None, pairs = False):\n",
    "        basis = []\n",
    "        num_ele = []\n",
    "        for k in range(0,2**d):\n",
    "            b = self.int_to_bin(k, d)\n",
    "            if num != None:\n",
    "                if b.count('1') == num:\n",
    "                    if pairs:\n",
    "                        if np.all(b[::2] == b[1::2]):\n",
    "                            oper = self.bin_to_op(b)\n",
    "                            basis.append(oper)\n",
    "                            num_ele.append(k)\n",
    "                    else:\n",
    "                        oper = self.bin_to_op(b)\n",
    "                        basis.append(oper)\n",
    "                        num_ele.append(k)\n",
    "            else:\n",
    "                oper = self.bin_to_op(b)\n",
    "                basis.append(oper)\n",
    "        return basis, num_ele\n",
    "\n",
    "    def __init__(self, d, num = None, pairs = False, basis = None, num_ele = None):\n",
    "        self.d = d\n",
    "        self.num = num\n",
    "        self.m = num\n",
    "        # Si nos da la base, la levantamos (asumimos GC). Si no, la creamos\n",
    "        if basis is None:\n",
    "            self.base, self.num_ele = self.create_basis(d, num, pairs)\n",
    "        else:\n",
    "            self.base, self.num_ele = basis, num_ele\n",
    "        self.size = len(self.base)\n",
    "        self.canonicals = np.eye(self.size)\n",
    "        self.pairs = pairs\n",
    "\n",
    "    @staticmethod\n",
    "    def cdc(i, j):\n",
    "        return of.FermionOperator(((i,1),(j,0)))\n",
    "\n",
    "    @staticmethod\n",
    "    def cc(i, j):\n",
    "        return of.FermionOperator(((i,0),(j,0)))\n",
    "\n",
    "    # Del indice, cuenta el número de partículas\n",
    "    def num_idx(self, idx):\n",
    "        b = self.int_to_bin(idx, basis.d)\n",
    "        return b.count('1')\n",
    "\n",
    "    # Calculo de rho1 (via directa, lento, y solo definido en la base por ahora)\n",
    "    def rho_1(self, op):\n",
    "        # Necesitamos un índice, es?\n",
    "        if type(op) != int:\n",
    "            op = self.opr_to_idx(op)\n",
    "        mat = np.zeros((self.d, self.d))\n",
    "        for i in range(self.d):\n",
    "            for j in range(self.d):\n",
    "                cdc = self.cdc(j, i)\n",
    "                mat[i,j] = self.idx_mean_val(op, cdc)\n",
    "        return mat\n",
    "\n",
    "# Calculo de generadores de rho1\n",
    "def rho_1_gen(basis):\n",
    "    # Vamos a crear un hipersparse de TF, almacenamos los valores acá\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = (basis.d, basis.d, basis.size, basis.size)\n",
    "    d = basis.d\n",
    "    for i in tqdm(range(0, d)):\n",
    "        for j in range(0, d):\n",
    "            # Generamos el operador\n",
    "            op = basis.cdc(j, i)\n",
    "            #print(op)\n",
    "            if basis.num == None:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))\n",
    "            else:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extraemos la información\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([i, j, r, c])\n",
    "                values.append(v)\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "# Calculo de rho1 (via generadores) de un vector en la base canonica\n",
    "def rho_1(vect, rho_1_arrays):\n",
    "    if len(vect.shape) == 1: # vectores\n",
    "        return sparse.einsum('k,ijkl,l->ij', vect, rho_1_arrays, vect)\n",
    "    elif len(vect.shape) == 2: # mat densidad\n",
    "        return sparse.einsum('ijkl,kl->ij', rho_1_arrays, vect)\n",
    "    else: # mat densidad batcheadas\n",
    "        return sparse.einsum('bkl,ijkl->bij', vect, rho_1_arrays)\n",
    "\n",
    "# Calculo de indices de rho2kkbar\n",
    "def get_kkbar_indices(t_basis):\n",
    "    indices = []\n",
    "    for i, ind in enumerate(t_basis.num_ele):\n",
    "        v = t_basis.int_to_bin(ind, t_basis.d)\n",
    "        if np.all(v[::2] == v[1::2]):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "# Calculo de generadores de rho2\n",
    "def rho_2_gen(basis, t_basis, idx_list = []):\n",
    "    # Vamos a crear un hipersparse de TF, almacenamos los valores acá\n",
    "    d = basis.d\n",
    "    indices = []\n",
    "    values = []\n",
    "    if len(idx_list) == basis.m:\n",
    "        idx_list = idx_list\n",
    "    elif len(idx_list) == basis.m**4:\n",
    "        idx_list = np.unique(idx_list[:,0])\n",
    "    else:\n",
    "        idx_list = range(t_basis.size)\n",
    "    shape = (len(idx_list), len(idx_list), basis.size, basis.size)\n",
    "    for i, ii in tqdm(enumerate(idx_list), total=len(idx_list)):\n",
    "        for j, jj in enumerate(idx_list):\n",
    "            # Generamos el operador\n",
    "            op = t_basis.base[jj]*of.utils.hermitian_conjugated(t_basis.base[ii])\n",
    "            if basis.num == None:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))\n",
    "            else:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extraemos la información\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([i, j, r, c])\n",
    "                values.append(v)\n",
    "\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "# rho_m_gen aux func\n",
    "def process_chunk(args):\n",
    "    chunk, m_basis, basis, d, it_set = args\n",
    "    indices = []\n",
    "    values = []\n",
    "    for ii in chunk:\n",
    "        for jj in it_set:\n",
    "            # Generate the operator\n",
    "            op = m_basis.base[jj] * of.utils.hermitian_conjugated(m_basis.base[ii])\n",
    "            mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extract the information\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([ii, jj, r, c])\n",
    "                values.append(v)\n",
    "    return indices, values\n",
    "\n",
    "# Parallelized rho_m_gen\n",
    "def rho_m_gen(basis, m, num_workers=None):\n",
    "    if num_workers is None:\n",
    "        num_workers = cpu_count()  # Use all available CPUs by default\n",
    "    \n",
    "    indices = []\n",
    "    values = []\n",
    "    m_basis = fixed_basis(basis.d, num=m, pairs=basis.pairs)\n",
    "    shape = (m_basis.size, m_basis.size, basis.size, basis.size)\n",
    "\n",
    "    it_set = np.arange(m_basis.size)\n",
    "    chunks = np.array_split(it_set, num_workers)  # Split `it_set` into chunks for each worker\n",
    "\n",
    "    # Use multiprocessing Pool for parallel processing\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        # Pass arguments as tuples instead of using a lambda\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(\n",
    "                    process_chunk, \n",
    "                    [(chunk, m_basis, basis, basis.d, it_set) for chunk in chunks]\n",
    "                ),\n",
    "                total=num_workers\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Collect results from all processes\n",
    "    for indices_chunk, values_chunk in results:\n",
    "        indices.extend(indices_chunk)\n",
    "        values.extend(values_chunk)\n",
    "\n",
    "    # Construct the sparse array\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "def rho_m(vect, rho_m_arrays):\n",
    "    return sparse.einsum('k,ijkl,l->ij', vect, rho_m_arrays, vect)\n",
    "\n",
    "# Calculo de rho2 (via generadores) de un estado en la base canonica\n",
    "def rho_2(vect, rho_2_arrays):\n",
    "    if len(vect.shape) == 1: # vectores SOLO RHO2 COMPLETA\n",
    "        return sparse.einsum('k,ijkl,l->ij', vect, rho_2_arrays, vect)\n",
    "    elif len(vect.shape) == 2: # mat densidad SOLO RHO2 COMPLETA\n",
    "        return sparse.einsum('ijkl,kl->ij', rho_2_arrays, vect)\n",
    "    else: # mat densidad batcheadas\n",
    "        return sparse.einsum('bkl,ijkl->bij', vect, rho_2_arrays)\n",
    "\n",
    "# Calculo de generadores de K (usado para quasiparticles) WIP SPARSE\n",
    "def k_gen(basis):\n",
    "    mat = np.zeros((basis.d, basis.d, basis.size, basis.size))\n",
    "    d = basis.d\n",
    "    for i in tqdm(range(0, d), total=d):\n",
    "        for j in range(0, d):\n",
    "            op = basis.cc(j, i)\n",
    "            if basis.num == None:\n",
    "                mat[i,j,::] = np.real(of.get_sparse_operator(op, n_qubits=d)).todense()\n",
    "            else:\n",
    "                mat[i,j,::] = np.real(of.get_sparse_operator(op, n_qubits=d)).todense()[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "    return mat\n",
    "\n",
    "def k_vect(vect, k_gen):\n",
    "    return np.einsum('k,ijkl,l->ij', vect, k_gen, vect)\n",
    "\n",
    "# Calculo la matrix rho de cuasipartículas  WIP SPARSE\n",
    "def rho_qsp(vect, rho_1_arrays, k_arrays, rho1 = None):\n",
    "    if type(rho1) == None:\n",
    "        rho1 = rho_1(vect, rho_1_arrays)\n",
    "    k = k_vect(vect, k_arrays)\n",
    "\n",
    "    mat = np.block([[rho1, k], [-np.conjugate(k), np.eye(rho_1_arrays.shape[0])-np.conjugate(rho1)]])\n",
    "    return mat\n",
    "\n",
    "# Devuelve los indices que tienen a level ocupado\n",
    "def level_proy(d, level):\n",
    "    ids = []\n",
    "    for k in range(0,2**d):\n",
    "        b = fixed_basis.int_to_bin(k, d)\n",
    "        if b[level] == '1':\n",
    "            ids.append(k)\n",
    "    arr = np.zeros(2**d)\n",
    "    arr[np.array(ids)] = 1\n",
    "    return arr, ids\n",
    "\n",
    "def parity_levels(d):\n",
    "    rng = range(2**d)\n",
    "    binary_repr = np.vectorize(np.binary_repr)(rng)\n",
    "    ones_c = np.char.count(binary_repr, '1')\n",
    "    return np.array(rng)[ones_c % 2 == 1] # seleccionamos estados impares\n",
    "\n",
    "# Devuelve el vector postmedido\n",
    "def measure(basis, vect, level = 1):\n",
    "    l_arr, l_ids = level_proy(basis.d, level)\n",
    "    proy_v = vect * l_arr\n",
    "    comp_arr = np.logical_not(l_arr).astype(int)\n",
    "    comp_v = vect * comp_arr\n",
    "    norm = lambda v: v / np.linalg.norm(v)\n",
    "    return norm(proy_v), norm(comp_v)\n",
    "\n",
    "def entropy(rho, m):\n",
    "    S_fun = lambda rho: -1*np.trace(rho @ scipy.linalg.logm(rho)) / np.log(2)\n",
    "    ent = S_fun(rho) / (np.log2(scipy.special.binom(basis.d, m)))\n",
    "    return ent\n",
    "\n",
    "# Levanta bases de QChem\n",
    "def build_csv_basis(csvf, d):\n",
    "    # Construimos la base\n",
    "    ops = []\n",
    "    with open(csvf, 'r') as basis:\n",
    "        num_ele = []\n",
    "        # Contar los niveles\n",
    "        m_level = 0\n",
    "        # Creamos operadores\n",
    "        for l in basis.read().splitlines()[4:]:\n",
    "            natop = [int(x) for x in l.split(' ')[1:]] # Operador en forma de lista\n",
    "            #print(natop)\n",
    "            op = of.FermionOperator(([(i, 1) for i in natop]))\n",
    "            ops.append(op)\n",
    "            # Contamos niveles\n",
    "            m_level = max(m_level, *natop)\n",
    "            # Determinamos el índice\n",
    "            natop_to_int = lambda x: np.sum([2**(d-1-i) for i in x])\n",
    "            num_ele.append(natop_to_int(natop))\n",
    " \n",
    "        # Determinamos m y d\n",
    "        num = len(natop)\n",
    "        #assert d == m_level+1\n",
    "\n",
    "    return fixed_basis(d, num = num, pairs = False, basis = ops, num_ele=num_ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido al número de niveles (innecesarios) en el core, el objetivo es calcular la base natural (a partir de rho1), y proyectar el fundamental sobre el subespacio generado por los estados no ocupados. Allí, buscamos la descomposición, y luego volvemos a la base original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aux func\n",
    "def remove_null_terms(op):\n",
    "    op_nn = of.FermionOperator.zero()\n",
    "    terms = list(op.terms.items())\n",
    "    act_idx = lambda tt: np.array([i[0] for i in tt[0]])\n",
    "    filtered_terms = []\n",
    "\n",
    "    for term in terms:\n",
    "        acts = np.array(act_idx(term))\n",
    "        u, c = np.unique(acts, return_counts=True)\n",
    "        if np.max(c) == 1:\n",
    "            filtered_terms.append(term)\n",
    "\n",
    "    return filtered_terms\n",
    "\n",
    "def op_to_rep(basis, op): # CHEQUEADO\n",
    "    op = -1*of.transforms.normal_ordered(op)\n",
    "    terms = list(op.terms.items())\n",
    "    act_idx = lambda tt: [i[0] for i in tt[0]]\n",
    "    vect = np.zeros(basis.size)\n",
    "\n",
    "    for term in terms:\n",
    "        act = act_idx(term)\n",
    "        nele = np.sum([2**(basis.d-1-i) for i in act]) # si\n",
    "        nele_idx = np.argwhere(basis.num_ele == nele)[0][0]\n",
    "        vect[nele_idx] += term[1]\n",
    "    \n",
    "    return vect\n",
    "    \n",
    "def build_basis_from_vect(basis, vect, tol = 1e-10):\n",
    "        ops = []\n",
    "        num_ele = []\n",
    "        vect_pro = []\n",
    "        for idx, coord in enumerate(vect):\n",
    "                if np.abs(coord) > tol:\n",
    "                        ops.append(basis.base[idx])\n",
    "                        num_ele.append(basis.num_ele[idx])\n",
    "                        vect_pro.append(vect[idx])\n",
    "        return fixed_basis(basis.d, num = basis.num, pairs = False, basis = ops, num_ele=num_ele), np.array(vect_pro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado la base, una rotación entre los 1SP states y un vector (representado en basis)\n",
    "# devuelve la representación en la base natural\n",
    "def natural_basis_rotation(basis, C, vect):\n",
    "    # Calculamos la transformación de cada generador\n",
    "    targ_sp = []\n",
    "    for i in range(basis.d):\n",
    "        op = np.sum([of.FermionOperator(((basis.d-1-j,1)),C[i,j]) for j in range(basis.d) if np.abs(C[i,j]) > 1e-5])\n",
    "        targ_sp.append(op)\n",
    "\n",
    "    targ_sp.reverse()\n",
    "\n",
    "    # Reemplazamos en el fundamental\n",
    "    vect_op = np.sum([vect[i] * basis.base[i] for i in range(len(vect))])\n",
    "    terms = list(vect_op.terms.items())\n",
    "\n",
    "    vect_op_t = of.FermionOperator.zero()\n",
    "    for term in terms:\n",
    "        # Construimos el término\n",
    "        act_idx = lambda tt: [i[0] for i in tt[0]]\n",
    "        tt = np.prod([targ_sp[i] for i in act_idx(term)])\n",
    "        vect_op_t += term[1] * tt\n",
    "        \n",
    "    # Filtramos los términos nulos\n",
    "    f_terms = remove_null_terms(vect_op_t)\n",
    "    vect_op_ft = of.FermionOperator.zero()\n",
    "    for ft in f_terms:\n",
    "        vect_op_ft += of.FermionOperator(ft[0],ft[1])\n",
    "\n",
    "    # Calculamos la representación en la base\n",
    "    ext_basis = fixed_basis(basis.d, basis.m)\n",
    "    res = op_to_rep(ext_basis, vect_op_ft)\n",
    "    res = 1/np.linalg.norm(res) * res\n",
    "\n",
    "    return res, vect_op_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinación de estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cargamos el input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 25.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Levantamos la base, y calculamos rho1\n",
    "basis = build_csv_basis('hf_basis', 12)\n",
    "rho_1_arrays = rho_m_gen(basis, 1, num_workers=32)\n",
    "\n",
    "# Levantamos el fundanental d=3\n",
    "vect = [7.211630245189536e-01,4.206455224775346e-02,-2.285388031865260e-12,1.699211387138645e-12,-4.129479393831875e-03,-3.823465330043704e-07,4.206455225178431e-02,-6.901551297130625e-01,2.105502564059137e-12,-1.565639815440850e-12,-4.122956845587538e-03,-3.755879654736101e-05,-7.228479653547532e-12,6.636332640706462e-12,-9.140952135390417e-04,-4.046086775026300e-16,8.239170289440526e-14,2.416202424789693e-16,-8.029397050081800e-13,7.469929098902930e-13,-1.075293384255381e-14,-9.140952135362526e-04,4.469835410063215e-15,5.163385528935227e-17,-4.129479393815261e-03,-4.122956845567992e-03,3.604262375317366e-14,-2.262779577530237e-14,-1.075992639441983e-03,-2.588630943109245e-05,-3.823465329666192e-07,-3.755879654741322e-05,5.671459804258443e-17,-2.094441474950918e-16,-2.588630943109360e-05,-8.771828180833955e-06]\n",
    "vect = np.array(vect)\n",
    "\n",
    "# Rho1 + Rho2\n",
    "rho_1_obj  = np.sort(np.concatenate([np.repeat(1/2, 2*2), np.repeat(1, 4*2)]))\n",
    "rho_2_obj = np.sort(np.concatenate([np.repeat(1/2, 8*2+16), np.repeat(1, 6*2+17), np.repeat(0, 5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 23.49it/s]\n",
      "100%|██████████| 32/32 [00:36<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cambio a base natural \n",
    "rho_1 = rho_m(vect, rho_1_arrays).todense()\n",
    "evals, evects = scipy.linalg.eigh(rho_1)\n",
    "C = evects\n",
    "vect_pro, op_pro = natural_basis_rotation(basis, C, vect)\n",
    "# Calculamos la base extendida, donde vive vect_pro y restringimos\n",
    "ext_basis = fixed_basis(basis.d, basis.m)\n",
    "basis_pro, vect_pro = build_basis_from_vect(ext_basis, vect_pro)\n",
    "# Calculamos los arrays en esta base\n",
    "rho_1_arrays = rho_m_gen(basis_pro, 1, num_workers=32)\n",
    "rho_2_arrays = rho_m_gen(basis_pro, 2, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# Input\n",
    "\n",
    "# Aux functions\n",
    "r_eig = lambda x: np.sort(np.real(np.linalg.eigvals(x.todense())))\n",
    "k = 2 # Número de clusters\n",
    "\n",
    "def sparsity_error(A, k=2):\n",
    "    # L1\n",
    "    sparsity_term = np.sum(np.abs(A))\n",
    "\n",
    "    # Clustering \n",
    "    non_zero_coeffs = A[np.abs(A) > 1e-5]  # Sacamos los ceros\n",
    "    if len(non_zero_coeffs) > 0:\n",
    "        # Calculamos los clusters (k) y la distancia en ellos\n",
    "        centroids, _ = kmeans(non_zero_coeffs, k)\n",
    "        cluster_labels, distances = vq(non_zero_coeffs, centroids)\n",
    "        cluster_error = np.sum(distances**2) \n",
    "    else:\n",
    "        cluster_error = 0\n",
    "\n",
    "    loss = 1 * sparsity_term + 2 * cluster_error\n",
    "    return loss\n",
    "\n",
    "# Loss definition\n",
    "def loss_fun(vect):\n",
    "    # Rho 2 loss\n",
    "    rho = rho_m(vect, rho_2_arrays)\n",
    "    eigv = r_eig(rho)\n",
    "    lrho2 = np.linalg.norm(rho_2_obj-eigv)\n",
    "    # Rho 1 loss\n",
    "    rho = rho_m(vect, rho_1_arrays)\n",
    "    eigv = r_eig(rho)\n",
    "    lrho1 = np.linalg.norm(rho_1_obj-eigv)\n",
    "    # L1 + clustering loss\n",
    "    l1 = sparsity_error(vect, k) \n",
    "\n",
    "    #print(lrho2, lrho1, l1)\n",
    "    return lrho2 + lrho1 + 1/2*l1\n",
    "\n",
    "opt = scipy.optimize.minimize(loss_fun, vect_pro, method='L-BFGS-B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 1.1789452999374304\n",
      "        x: [-1.115e-03  1.208e-03 ...  1.187e-03 -7.072e-01]\n",
      "      nit: 11\n",
      "      jac: [-1.195e+00  3.999e-01 ...  2.300e-01 -5.037e+00]\n",
      "     nfev: 1232\n",
      "     njev: 77\n",
      " hess_inv: <15x15 LbfgsInvHessProduct with dtype=float64>\n",
      "[-1.11479488e-03  1.20847971e-03 -1.12196875e-03  1.20837150e-03\n",
      " -9.99996232e-06  1.62021695e-03 -2.74187038e-04  1.00462928e-03\n",
      "  8.34930618e-04  1.20963641e-03 -1.18130874e-03  7.07007588e-01\n",
      " -1.20426990e-03  1.18745490e-03 -7.07228056e-01]\n",
      "2.349528518023165\n",
      "[0.5 0.5 0.5 0.5 1.  1.  1.  1.  1.  1.  1.  1. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(opt)\n",
    "print(opt.x)\n",
    "print(sparsity_error(opt.x, k=k))\n",
    "print(rho_1_obj)\n",
    "np.round(r_eig(rho_m(opt.x, rho_1_arrays)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7072280557168331 [0^ 1^ 2^ 3^ 4^ 5^ 6^ 7^ 8^ 9^] +\n",
       "0.7070075877513028 [0^ 1^ 2^ 3^ 4^ 5^ 6^ 7^ 10^ 11^]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res = of.FermionOperator.zero()\n",
    "tol = 1e-2\n",
    "for idx, coord in enumerate(opt.x):\n",
    "    final_res += basis_pro.base[idx] * coord if np.abs(coord) > tol else 0\n",
    "\n",
    "final_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que los eig de rho1 se preservan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000000000000002 9.999999999999996\n",
      "[0.47807955 0.47807955 0.52192329 0.52192329 0.99999884 0.99999884\n",
      " 0.99999916 0.99999916 0.99999916 0.99999916 1.         1.        ] [0.47807947 0.47807947 0.52192336 0.52192336 0.99999884 0.99999884\n",
      " 0.99999916 0.99999916 0.99999916 0.99999916 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Cálculo de base natural\n",
    "rho_1 = rho_m(vect, rho_1_arrays).todense()\n",
    "evals, evects = scipy.linalg.eigh(rho_1)\n",
    "C = evects\n",
    "\n",
    "res, vect_op_ft = natural_basis_rotation(basis, C, vect)\n",
    "\n",
    "ext_basis = fixed_basis(basis.d, basis.m)\n",
    "rho_1_arrays_n = rho_m_gen(ext_basis, 1, num_workers=32)\n",
    "rho_1_n = rho_m(res, rho_1_arrays_n).todense()\n",
    "print(np.trace(rho_1_n), np.trace(rho_1))\n",
    "\n",
    "evv = lambda vv: np.sort(np.real(np.linalg.eigvals(vv)))\n",
    "print(evv(rho_1), evv(rho_1_n))\n",
    "\n",
    "rep_to_op = lambda vect: np.sum([vect[i] * basis.base[i] for i in range(len(vect))])\n",
    "#unique_ele(vect_op_ft), unique_ele(rep_to_op(vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que la composición, es la identidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.7211630244701693 [10^ 9^ 8^ 7^ 6^ 4^ 3^ 2^ 1^ 0^] +\n",
       " -0.04206455117791357 [10^ 9^ 8^ 7^ 6^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 0.0041294638743610106 [10^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 1.722640320119456e-06 [10^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 1^] +\n",
       " -0.04206456374360802 [11^ 9^ 8^ 7^ 6^ 4^ 3^ 2^ 1^ 0^] +\n",
       " 0.6901550609047076 [11^ 9^ 8^ 7^ 6^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 0.004122938575493033 [11^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 3.7602921241802925e-05 [11^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 1^] +\n",
       " 0.0009140907457695419 [11^ 10^ 8^ 7^ 6^ 5^ 4^ 2^ 1^ 0^] +\n",
       " 2.9256080028949687e-08 [11^ 10^ 8^ 7^ 6^ 5^ 4^ 3^ 1^ 0^] +\n",
       " -2.907592256480154e-08 [11^ 10^ 9^ 7^ 6^ 5^ 4^ 2^ 1^ 0^] +\n",
       " 0.0009140942661331014 [11^ 10^ 9^ 7^ 6^ 5^ 4^ 3^ 1^ 0^] +\n",
       " 0.0041294638037233785 [11^ 10^ 9^ 8^ 6^ 4^ 3^ 2^ 1^ 0^] +\n",
       " 0.004122938790304289 [11^ 10^ 9^ 8^ 6^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 0.0010758547983938326 [11^ 10^ 9^ 8^ 6^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 2.5887452734296404e-05 [11^ 10^ 9^ 8^ 6^ 5^ 4^ 3^ 2^ 1^] +\n",
       " 1.7226422573101622e-06 [11^ 10^ 9^ 8^ 7^ 4^ 3^ 2^ 1^ 0^] +\n",
       " 3.760292136590614e-05 [11^ 10^ 9^ 8^ 7^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 2.5872080798175898e-05 [11^ 10^ 9^ 8^ 7^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 8.765832766734672e-06 [11^ 10^ 9^ 8^ 7^ 5^ 4^ 3^ 2^ 1^],\n",
       " array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -8.76583318e-06, -2.58874540e-05,  0.00000000e+00,\n",
       "         0.00000000e+00, -3.76029230e-05, -1.72264040e-06,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.58720820e-05,\n",
       "        -1.07585485e-03,  0.00000000e+00,  0.00000000e+00, -4.12293877e-03,\n",
       "        -4.12946407e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.14094310e-04, -2.92560814e-08,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.90759239e-08, -9.14090789e-04,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -3.76029232e-05,\n",
       "        -4.12293899e-03,  0.00000000e+00,  0.00000000e+00, -6.90155094e-01,\n",
       "         4.20645532e-02, -1.72264234e-06, -4.12946400e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  4.20645657e-02,  7.21163059e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00]),\n",
       " -0.7211630245189536 [10^ 9^ 8^ 7^ 6^ 4^ 3^ 2^ 1^ 0^] +\n",
       " -0.04206455225178431 [10^ 9^ 8^ 7^ 6^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 0.004129479393815261 [10^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 3.823465329666192e-07 [10^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 1^] +\n",
       " -0.04206455224775346 [11^ 9^ 8^ 7^ 6^ 4^ 3^ 2^ 1^ 0^] +\n",
       " 0.6901551297130625 [11^ 9^ 8^ 7^ 6^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 0.004122956845567992 [11^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 3.755879654741322e-05 [11^ 9^ 8^ 7^ 6^ 5^ 4^ 3^ 2^ 1^] +\n",
       " 0.0009140952135390417 [11^ 10^ 8^ 7^ 6^ 5^ 4^ 2^ 1^ 0^] +\n",
       " 0.0009140952135362526 [11^ 10^ 9^ 7^ 6^ 5^ 4^ 3^ 1^ 0^] +\n",
       " 0.004129479393831875 [11^ 10^ 9^ 8^ 6^ 4^ 3^ 2^ 1^ 0^] +\n",
       " 0.004122956845587538 [11^ 10^ 9^ 8^ 6^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 0.001075992639441983 [11^ 10^ 9^ 8^ 6^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 2.58863094310936e-05 [11^ 10^ 9^ 8^ 6^ 5^ 4^ 3^ 2^ 1^] +\n",
       " 3.823465330043704e-07 [11^ 10^ 9^ 8^ 7^ 4^ 3^ 2^ 1^ 0^] +\n",
       " 3.755879654736101e-05 [11^ 10^ 9^ 8^ 7^ 5^ 3^ 2^ 1^ 0^] +\n",
       " 2.588630943109245e-05 [11^ 10^ 9^ 8^ 7^ 5^ 4^ 3^ 2^ 0^] +\n",
       " 8.771828180833955e-06 [11^ 10^ 9^ 8^ 7^ 5^ 4^ 3^ 2^ 1^])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res, vect_op_ft = natural_basis_rotation(basis, C, vect)\n",
    "res2, vect_op_ft2 = natural_basis_rotation(ext_basis, C.T, res)\n",
    "\n",
    "vect_op = np.sum([vect[i] * basis.base[i] for i in range(len(vect))])\n",
    "\n",
    "of.transforms.normal_ordered(vect_op_ft2), res2, of.transforms.normal_ordered(vect_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2, 6}, {0, 1, 2, 6})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def unique_ele(op):\n",
    "    terms = list(vect_op.terms.items())\n",
    "    act_idx = lambda tt: [i[0] for i in tt[0]]\n",
    "    terms_set = []\n",
    "    for term in terms:\n",
    "        terms_set.append(act_idx(term))\n",
    "    return set(terms_set[0]).intersection(*terms_set[1:])\n",
    "\n",
    "unique_ele(vect_op_ft), unique_ele(vect_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:00<00:00,  5.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Verifiquemos que los orbitales son ortogonales\n",
    "op_arr = np.zeros((basis.d,basis.d),dtype=object)\n",
    "sp_basis = fixed_basis(basis.d, 1)\n",
    "for i in tqdm(range(basis.d)):\n",
    "    for j in range(basis.d):\n",
    "        oi = np.real(of.get_sparse_operator(targ_sp[i], n_qubits=basis.d))\n",
    "        oj = np.real(of.get_sparse_operator(targ_sp[j], n_qubits=basis.d))\n",
    "        # Sin daguear y dagueado\n",
    "        assert len((oi * oj + oj * oi).data) == 0\n",
    "        assert len((oi.T * oj.T + oj.T * oi.T).data) == 0\n",
    "        # Términos cruzados\n",
    "        op_arr[i,j] = oi * oj.T + oj.T * oi\n",
    "        sh = op_arr[i,j].shape[0]\n",
    "        if i != j:\n",
    "            assert np.allclose(np.zeros((sh,sh)),op_arr[i,j].todense())\n",
    "        else:\n",
    "            assert np.allclose(np.eye(sh),op_arr[i,j].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 -0.27936976320734497 1.0 [0^ 1^ 2^ 3^ 4^ 7^ 8^ 9^ 12^ 13^]\n",
      "13.0\n",
      "\n",
      "25 0.28996316812175205 1.0 [0^ 1^ 2^ 3^ 5^ 7^ 8^ 9^ 11^ 13^]\n",
      "12.0\n",
      "\n",
      "45 0.5718530568911167 1.0 [0^ 1^ 2^ 3^ 6^ 7^ 8^ 9^ 11^ 12^]\n",
      "3.0\n",
      "\n",
      "65 0.572154480816062 1.0 [0^ 1^ 2^ 4^ 5^ 7^ 8^ 9^ 10^ 13^]\n",
      "3.0\n",
      "\n",
      "85 0.2897326805359033 1.0 [0^ 1^ 2^ 4^ 6^ 7^ 8^ 9^ 10^ 12^]\n",
      "12.0\n",
      "\n",
      "105 -0.27954194550717076 1.0 [0^ 1^ 2^ 5^ 6^ 7^ 8^ 9^ 10^ 11^]\n",
      "13.0\n",
      "\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.33333333\n",
      " 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.75\n",
      " 0.75       0.75       0.75       1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "est = 0\n",
    "app_r = lambda x: np.round(1/(x**2), 0)\n",
    "for i, ii in enumerate(opt.x):\n",
    "    if np.abs(ii) > 0.1:\n",
    "        print(i, ii, basis.base[i])\n",
    "        if np.abs(ii) > 0.2:\n",
    "            print(app_r(ii))\n",
    "            est += 1/np.sqrt(app_r(ii)) * basis.canonicals[i]\n",
    "            print('')\n",
    "\n",
    "#(1/np.sqrt(3), 1/np.sqrt(12))\n",
    "#print(est)\n",
    "est = 1/np.sqrt(12) * (-basis.canonicals[5]+basis.canonicals[25]+basis.canonicals[85]-basis.canonicals[105])+1/np.sqrt(3)*(basis.canonicals[45]+basis.canonicals[65])\n",
    "\n",
    "print(r_eig(rho_m(est, rho_2_arrays)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.39649654e-18, 2.27759896e-17, 2.27759896e-17, 2.97340303e-17,\n",
       "       1.05847838e-08, 1.05847839e-08, 8.12469946e-02, 8.12469946e-02,\n",
       "       8.12469946e-02, 8.12469946e-02, 8.12469946e-02, 8.12469946e-02,\n",
       "       8.26670825e-02, 8.26670825e-02, 8.26670825e-02, 8.26670825e-02,\n",
       "       8.26670825e-02, 8.26670825e-02, 3.36085923e-01, 3.36085923e-01,\n",
       "       3.36085923e-01, 3.36085923e-01, 3.36085923e-01, 3.36085923e-01,\n",
       "       7.48001237e-01, 7.48001237e-01, 7.51998753e-01, 7.51998753e-01])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_eig(rho_m(vect, rho_2_arrays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.64692802e-01,  2.77029463e-13,  6.04225310e-13, -6.02451636e-13,\n",
       "       -2.56718779e-13,  1.43759419e-01, -2.76373045e-13,  4.64692802e-01,\n",
       "        6.78313552e-13,  6.75558510e-13, -1.43759419e-01,  2.56506937e-13,\n",
       "       -6.03653495e-13, -6.77704300e-13, -6.25591975e-14, -2.87518838e-01,\n",
       "       -6.29232018e-13, -5.60633058e-13,  6.01429896e-13, -6.75919400e-13,\n",
       "       -2.87518838e-01, -6.20739380e-14, -6.26983384e-13,  5.59008839e-13,\n",
       "        2.55745844e-13, -1.43759419e-01,  6.28758833e-13,  6.27003686e-13,\n",
       "        4.00074963e-01, -2.38304993e-13,  1.43759419e-01, -2.55921509e-13,\n",
       "        5.60076347e-13, -5.58040539e-13,  2.38229636e-13, -4.00074963e-01])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = [-4.646928018967011e-01,2.770294629368069e-13,6.042253100720720e-13,-6.024516357133285e-13,-2.567187786718633e-13,1.437594192304828e-01,-2.763730452330614e-13,4.646928018967681e-01,6.783135520862164e-13,6.755585098225312e-13,-1.437594192304206e-01,2.565069368880155e-13,-6.036534951757788e-13,-6.777043000828106e-13,-6.255919748617283e-14,-2.875188384604817e-01,-6.292320178844996e-13,-5.606330583371935e-13,6.014298958703158e-13,-6.759194003610720e-13,-2.875188384604817e-01,-6.207393804663961e-14,-6.269833844031960e-13,5.590088393571927e-13,2.557458444682729e-13,-1.437594192304207e-01,6.287588334290853e-13,6.270036860946324e-13,4.000749631766127e-01,-2.383049928519640e-13,1.437594192304827e-01,-2.559215089660516e-13,5.600763473792744e-13,-5.580405389843103e-13,2.382296361695720e-13,-4.000749631765536e-01]\n",
    "vect = np.array(vect)\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.39649654e-18+0.00000000e+00j, 2.27759896e-17-1.60872919e-17j,\n",
       "       2.27759896e-17+1.60872919e-17j, 2.97340303e-17+0.00000000e+00j,\n",
       "       1.05847838e-08+0.00000000e+00j, 1.05847839e-08+0.00000000e+00j,\n",
       "       8.12469946e-02+0.00000000e+00j, 8.12469946e-02+0.00000000e+00j,\n",
       "       8.12469946e-02+0.00000000e+00j, 8.12469946e-02+0.00000000e+00j,\n",
       "       8.12469946e-02+0.00000000e+00j, 8.12469946e-02+0.00000000e+00j,\n",
       "       8.26670825e-02+0.00000000e+00j, 8.26670825e-02+0.00000000e+00j,\n",
       "       8.26670825e-02+0.00000000e+00j, 8.26670825e-02+0.00000000e+00j,\n",
       "       8.26670825e-02+0.00000000e+00j, 8.26670825e-02+0.00000000e+00j,\n",
       "       3.36085923e-01+0.00000000e+00j, 3.36085923e-01+0.00000000e+00j,\n",
       "       3.36085923e-01+0.00000000e+00j, 3.36085923e-01+0.00000000e+00j,\n",
       "       3.36085923e-01+0.00000000e+00j, 3.36085923e-01+0.00000000e+00j,\n",
       "       7.48001237e-01+0.00000000e+00j, 7.48001237e-01+0.00000000e+00j,\n",
       "       7.51998753e-01+0.00000000e+00j, 7.51998753e-01+0.00000000e+00j])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.linalg.eigvals(rho_m(vect, rho_2_arrays).todense()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
